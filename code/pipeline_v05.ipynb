{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cd5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training data\n",
    "# Clean/preprocess/transform the data\n",
    "# Train a machine learning model\n",
    "# Evaluate and optimise the model\n",
    "# Clean/preprocess/transform new data\n",
    "# Fit the model on new data to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636438b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,recall_score,confusion_matrix, roc_auc_score, precision_score, f1_score, roc_curve, auc, plot_confusion_matrix,plot_roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9a9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name: X_train_des\n",
      "file name: y_test_des\n",
      "file name: X_test_des\n",
      "file name: train_month_1\n",
      "file name: data_merged\n",
      "file name: train_month_2\n",
      "file name: test_month_1\n",
      "file name: test_month_3\n",
      "file name: test_month_2\n",
      "file name: y_train_des\n",
      "file name: train_month_3_with_target\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "mypath = \"../data/\"\n",
    "mydata = load_data.get_file_names(mypath)\n",
    "data_files = load_data.load_copy_data(mydata, mypath)\n",
    "\n",
    "test = data_files['data_merged']\n",
    "data = data_files['data_merged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6913bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin area codes by 1000s \n",
    "\n",
    "# Test Case\n",
    "# testtest = pd.DataFrame({\"value\": (0, 2050, 4100, 4101, 6150, 4102, 8200, 2060, 8210, 8211, 2070, 4120, 4121, 4122, 4130, 6180, 6181, 6182, 6183, 9000,)})\n",
    "# labels = [\"{}_area_code\".format(i) for i in range(0, 10000, 1000)]\n",
    "# testtest[\"area_cat\"] = pd.cut(testtest.value, range(0, 10005, 1000), right=False, labels=labels)\n",
    "\n",
    "labels = [\"{}_area_code\".format(i) for i in range(0, 10000, 1000)]\n",
    "data[\"area_cat\"] = pd.cut(data.customer_postal_code_x, range(0, 10005, 1000), right=False, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b16f475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal_insurance_21\n",
      "bal_insurance_23\n",
      "bal_personal_loan\n",
      "bal_mortgage_loan\n",
      "bal_current_account\n",
      "bal_pension_saving\n",
      "bal_savings_account\n"
     ]
    }
   ],
   "source": [
    "# Get % Change from time point 1 to 2, 2 to 3, 1 to 3\n",
    "\n",
    "# bal_insurance_21: balance on \"tak 21\" life insurance\n",
    "# bal_insurance_23: balance on \"tak 23\" life insurance\n",
    "# cap_life_insurance_fixed_cap: capital for life insurance with fixed capital\n",
    "# cap_life_insurance_decreasing_cap: capital for life insurance with decreasing capital\n",
    "# prem_fire_car_other_insurance: premiums paid for fire/car/other insurance\n",
    "# bal_personal_loan: outstanding balance on personal loans\n",
    "# bal_mortgage_loan: outstanding balance on mortgage loans\n",
    "# bal_current_account: balance on current (checkings) accounts\n",
    "# bal_pension_saving: balance on pension (retirement) savings accounts\n",
    "# bal_savings_account: balance on savings accounts\n",
    "# bal_current_account_starter: balance on starter current (checkings) accounts\n",
    "# bal_savings_account_starter: balance on starter savings accounts\n",
    "\n",
    "def percentage_change(col1,col2):\n",
    "    return ((col2 - col1) / col1) * 100\n",
    "\n",
    "\n",
    "list_balances = [['bal_insurance_21_x', 'bal_insurance_21_y', 'bal_insurance_21'],\n",
    "                 ['bal_insurance_23_x', 'bal_insurance_23_y', 'bal_insurance_23'],\n",
    "                 ['bal_personal_loan_x', 'bal_personal_loan_y', 'bal_personal_loan'],\n",
    "                 ['bal_mortgage_loan_x', 'bal_mortgage_loan_y', 'bal_mortgage_loan'],\n",
    "                 ['bal_current_account_x', 'bal_current_account_y', 'bal_current_account'],\n",
    "                 ['bal_pension_saving_x', 'bal_pension_saving_y', 'bal_pension_saving'],\n",
    "                 ['bal_savings_account_x', 'bal_savings_account_y', 'bal_savings_account'],\n",
    "                ]\n",
    "\n",
    "for balance_type in list_balances:\n",
    "    print(balance_type[2])\n",
    "    data['{}_1'.format(balance_type[2])] = percentage_change(data[balance_type[0]],data[balance_type[1]]) \n",
    "    data['{}_2'.format(balance_type[2])] = percentage_change(data[balance_type[1]],data[balance_type[2]]) \n",
    "    data['{}_3'.format(balance_type[2])] = percentage_change(data[balance_type[0]],data[balance_type[2]]) \n",
    "\n",
    "    data['{}_1'.format(balance_type[2])] = data['{}_1'.format(balance_type[2])].fillna(0)\n",
    "    data['{}_2'.format(balance_type[2])] = data['{}_2'.format(balance_type[2])].fillna(0)\n",
    "    data['{}_3'.format(balance_type[2])] = data['{}_3'.format(balance_type[2])].fillna(0)                                                     \n",
    "                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4222fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct test, train set\n",
    "X = data.drop('target',axis=1)\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "192816dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 49408, 1: 1549})\n",
      "Counter({0: 49408, 1: 24704})\n",
      "Counter({0: 3098, 1: 1549})\n"
     ]
    }
   ],
   "source": [
    " # summarize class distribution\n",
    "print(Counter(y_train))\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy=0.5)\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
    "# summarize class distribution\n",
    "print(Counter(y_over))\n",
    "print(Counter(y_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64964d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes to process dates to days and Children status to binary\n",
    "\n",
    "class InbetweenDays(BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, documents, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x_dataset):\n",
    "        list_dates = ['customer_since_all_x', 'customer_since_bank_x', 'customer_birth_date_x']\n",
    "\n",
    "        #Convert date columns into datetime format\n",
    "        x_dataset['base_dt'] = pd.to_datetime('2018-01-01')\n",
    "        x_dataset[list_dates] = x_dataset[list_dates].apply(pd.to_datetime)\n",
    "\n",
    "        for col in list_dates:\n",
    "            x_dataset[col] = abs(x_dataset['base_dt'].dt.year - x_dataset[col].dt.year)\n",
    "\n",
    "        #Drop columns (base_dt)\n",
    "        x_dataset = x_dataset.drop('base_dt', axis=1)\n",
    "    \n",
    "        return x_dataset\n",
    "    \n",
    "\n",
    "class ChildrenStatus(BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, documents, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x_dataset):\n",
    "        for column in ['customer_children', 'customer_children_y', 'customer_children_x']:\n",
    "            x_dataset[column].replace(['mature', 'young', 'onebaby', 'adolescent', 'preschool', 'grownup'], 'yes', inplace=True)\n",
    "            x_dataset[column].fillna('no', inplace=True)\n",
    "    \n",
    "        return x_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e04e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to preprocess\n",
    "\n",
    "# Features to drop\n",
    "drop_features = [\n",
    "    'Unnamed: 0',\n",
    "    'client_id', #ID not needed in the training data\n",
    "    'customer_education_x', #Remove education b/c missing > 70%\n",
    "    'customer_education_y', #\n",
    "    'customer_education',#\n",
    "]\n",
    "\n",
    "# Duplicated Columns to drop\n",
    "dup_cols = test.T.duplicated().reset_index()\n",
    "dup_cols_list = dup_cols.loc[dup_cols[0], 'index'].tolist()\n",
    "drop_features.extend(dup_cols_list)\n",
    "\n",
    "\n",
    "# Categorical Features to Preprocess\n",
    "categorical_features = [\n",
    "    'customer_relationship', 'customer_relationship_y', 'customer_relationship_x', \n",
    "    'customer_occupation_code_x',\n",
    "    'customer_children', 'customer_children_y', 'customer_children_x',\n",
    "    'customer_gender_x',\n",
    "    'area_cat',\n",
    "#     'customer_postal_code', 'customer_postal_code_y', 'customer_postal_code_x', #error!!! ValueError: Found unknown categories [3471] in column 12 during transform (during testing)\n",
    "    'customer_self_employed', 'customer_self_employed_y', 'customer_self_employed_x',\n",
    "]\n",
    "\n",
    "# Numerical Features to Preprocess\n",
    "numeric_features = [\n",
    "    'bal_insurance_21', 'bal_insurance_21_y', 'bal_insurance_21_x', \n",
    "    'bal_insurance_23', 'bal_insurance_23_y', 'bal_insurance_23_x',\n",
    "    'cap_life_insurance_fixed_cap', 'cap_life_insurance_fixed_cap_y', 'cap_life_insurance_fixed_cap_x',\n",
    "    'cap_life_insurance_decreasing_cap', 'cap_life_insurance_decreasing_cap_y', 'cap_life_insurance_decreasing_cap_x',\n",
    "    'prem_fire_car_other_insurance', 'prem_fire_car_other_insurance_y', 'prem_fire_car_other_insurance_x',\n",
    "    'bal_personal_loan', 'bal_personal_loan_y', 'bal_personal_loan_x',\n",
    "    'bal_mortgage_loan', 'bal_mortgage_loan_y', 'bal_mortgage_loan_x',\n",
    "    'bal_current_account', 'bal_current_account_y', 'bal_current_account_x',\n",
    "    'bal_pension_saving', 'bal_pension_saving_y', 'bal_pension_saving_x', \n",
    "    'bal_savings_account', 'bal_savings_account_y', 'bal_savings_account_x',\n",
    "    'bal_current_account_starter', 'bal_current_account_starter_y', 'bal_current_account_starter_x',\n",
    "    'bal_savings_account_starter', 'bal_savings_account_starter_y', 'bal_savings_account_starter_x',\n",
    "    'visits_distinct_so', 'visits_distinct_so_y', 'visits_distinct_so_x',\n",
    "    'visits_distinct_so_areas', 'visits_distinct_so_areas_y', 'visits_distinct_so_areas_x',\n",
    "    'customer_since_all_x', 'customer_since_bank_x', 'customer_birth_date_x',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53cb65e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['has_savings_account_starter_y',\n",
       " 'customer_since_all_y',\n",
       " 'customer_since_bank_y',\n",
       " 'customer_gender_y',\n",
       " 'customer_birth_date_y',\n",
       " 'customer_postal_code_y',\n",
       " 'customer_occupation_code_y',\n",
       " 'customer_education_y',\n",
       " 'customer_since_all',\n",
       " 'customer_since_bank',\n",
       " 'customer_gender',\n",
       " 'customer_birth_date',\n",
       " 'customer_postal_code',\n",
       " 'customer_occupation_code',\n",
       " 'customer_education']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of Duplicated Columns\n",
    "dup_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f540a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA with column mean, normalize numerical values\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('normalize', Normalizer()),\n",
    "])\n",
    "\n",
    "# Replace NA with column mode, encode categorical value to 0/1\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857e229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process pipeline that drops unnecessary features, transforms numerical and categorical values\n",
    "preprocessor = ColumnTransformer(remainder='passthrough',\n",
    "                                 transformers=[\n",
    "                                     ('drop_columns', 'drop', drop_features),\n",
    "                                     ('numeric', numeric_transformer, numeric_features),\n",
    "                                     ('categorical', categorical_transformer, categorical_features)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba064d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline from preprocessing to fitting a model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('inbetween_days', InbetweenDays()),\n",
    "    ('binarize_children', ChildrenStatus()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('catboost_weighted', CatBoostClassifier(verbose=False,random_state=0)),#,scale_pos_weight=2)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53fdd673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xc/tvrxkd8d2d71ksnxgn8wf9t40000gn/T/ipykernel_83274/4021551463.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_dataset['base_dt'] = pd.to_datetime('2018-01-01')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('inbetween_days', InbetweenDays()),\n",
       "                ('binarize_children', ChildrenStatus()),\n",
       "                ('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('drop_columns', 'drop',\n",
       "                                                  ['Unnamed: 0', 'client_id',\n",
       "                                                   'customer_education_x',\n",
       "                                                   'customer_education_y',\n",
       "                                                   'customer_education',\n",
       "                                                   'has_savings_account_starter_y',\n",
       "                                                   'customer_since_all_y',\n",
       "                                                   'customer_since_ba...\n",
       "                                                  ['customer_relationship',\n",
       "                                                   'customer_relationship_y',\n",
       "                                                   'customer_relationship_x',\n",
       "                                                   'customer_occupation_code_x',\n",
       "                                                   'customer_children',\n",
       "                                                   'customer_children_y',\n",
       "                                                   'customer_children_x',\n",
       "                                                   'customer_gender_x',\n",
       "                                                   'area_cat',\n",
       "                                                   'customer_self_employed',\n",
       "                                                   'customer_self_employed_y',\n",
       "                                                   'customer_self_employed_x'])])),\n",
       "                ('catboost_weighted',\n",
       "                 <catboost.core.CatBoostClassifier object at 0x7f9a5e357400>)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline.fit(X_train, y_train)\n",
    "pipeline.fit(X_over, y_over)\n",
    "#pipeline.fit(X_under, y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bc06b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9516\n",
      "Recall: 0.1099\n",
      "ROC_AUC: 0.5431\n",
      "Precision: 0.1205\n"
     ]
    }
   ],
   "source": [
    "# With scale_pos_weight=5, minority class gets 5 times more impact and 5 times more correction than errors made on the majority class.\n",
    "#catboost_5 = CatBoostClassifier(verbose=False,random_state=0,scale_pos_weight=5)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_pred),4)}')\n",
    "print(f'Recall: {round(recall_score(y_test, y_pred),4)}')\n",
    "print(f'ROC_AUC: {round(roc_auc_score(y_test, y_pred),4)}')\n",
    "print(f'Precision: {round(precision_score(y_test, y_pred),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3981d6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.968\n",
      "Recall: 0.2\n",
      "ROC_AUC: 0.5918\n",
      "Precision: 0.2\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {round(accuracy_score(y_test[:250], y_pred[:250]),4)}')\n",
    "print(f'Recall: {round(recall_score(y_test[:250], y_pred[:250]),4)}')\n",
    "print(f'ROC_AUC: {round(roc_auc_score(y_test[:250], y_pred[:250]),4)}')\n",
    "print(f'Precision: {round(precision_score(y_test[:250], y_pred[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef5dc409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555729984301413"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3b049a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Churners       0.97      0.98      0.98     12376\n",
      "    Churners       0.12      0.11      0.11       364\n",
      "\n",
      "    accuracy                           0.95     12740\n",
      "   macro avg       0.55      0.54      0.55     12740\n",
      "weighted avg       0.95      0.95      0.95     12740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Non-Churners', 'Churners']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f911d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1323e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7908a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4794b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c6755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a419095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9164\n",
      "Recall: 0.2418\n",
      "ROC_AUC: 0.589\n",
      "Precision: 0.1003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "# Pipeline from preprocessing to fitting a model\n",
    "pipeline2 = Pipeline(steps=[\n",
    "    ('inbetween_days', InbetweenDays()),\n",
    "    ('binarize_children', ChildrenStatus()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('LGBMClassifier', LGBMClassifier(random_state=0))\n",
    "#     ('logistic', LogisticRegression(random_state=0)),\n",
    "])\n",
    "\n",
    "pipeline2.fit(X_over, y_over)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred2 = pipeline2.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_pred2),4)}')\n",
    "print(f'Recall: {round(recall_score(y_test, y_pred2),4)}')\n",
    "print(f'ROC_AUC: {round(roc_auc_score(y_test, y_pred2),4)}')\n",
    "print(f'Precision: {round(precision_score(y_test, y_pred2),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54fefbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
