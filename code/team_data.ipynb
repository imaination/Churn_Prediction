{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e39f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipynb.fs.full.Get_Base_Data_00 import Time\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a68b844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name: train_month_1\n",
      "file name: train_month_2\n",
      "file name: test_month_1\n",
      "file name: test_month_3\n",
      "file name: test_month_2\n",
      "file name: train_month_3_with_target\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "mypath = \"../data/team_data/data/\"\n",
    "mydata = load_data.get_file_names(mypath)\n",
    "df = load_data.load_copy_data(mydata, mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0ced6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(left_df, right_df, merge_on, how, suffixes=(None,None)):\n",
    "    df_merge = left_df.merge(right_df, on=[merge_on], how=how, suffixes=suffixes)\n",
    "    print(f\"Shape of dataframe: {df_merge.shape}\")\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8fdc8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (63697, 77)\n",
      "Shape of dataframe: (63697, 116)\n"
     ]
    }
   ],
   "source": [
    "#Merge data (should be 39+38+39 columns = 118?, rows = 63697) with client_id as key\n",
    "df_merged = merge_df(df['train_month_1'], df['train_month_2'], 'client_id', 'outer', ('_m1', '_m2'))\n",
    "df_merged = merge_df(df_merged, df['train_month_3_with_target'], 'client_id', 'outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afadc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find and Drop duplicated features\n",
    "def drop_features(col_list, df):\n",
    "    drop_features = col_list\n",
    "    \n",
    "    # Duplicated Columns to drop\n",
    "    dup_cols = df.T.duplicated().reset_index()\n",
    "    dup_cols_list = dup_cols.loc[dup_cols[0], 'index'].tolist()\n",
    "    drop_features.extend(dup_cols_list)\n",
    "\n",
    "    data = df.drop(drop_features, axis=1)\n",
    "    \n",
    "    print(f'Dropped features: {drop_features}')\n",
    "    print(f'Raw merged data: {df.shape}')\n",
    "    print(f'Duplicated columns dropped: {data.shape}')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40e3a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped features: ['customer_education_m1', 'has_savings_account_starter_m2', 'customer_since_all_m2', 'customer_since_bank_m2', 'customer_gender_m2', 'customer_birth_date_m2', 'customer_postal_code_m2', 'customer_occupation_code_m2', 'customer_education_m2', 'customer_since_all', 'customer_since_bank', 'customer_gender', 'customer_birth_date', 'customer_postal_code', 'customer_occupation_code', 'customer_education']\n",
      "Raw merged data: (63697, 116)\n",
      "Duplicated columns dropped: (63697, 100)\n"
     ]
    }
   ],
   "source": [
    "#Drop duplicated features and customer education since it is missing 73% of data\n",
    "df_merged = drop_features(['customer_education_m1'], df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ac3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct test, train set\n",
    "X = df_merged.drop('target',axis=1)\n",
    "y = df_merged['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e752b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(mypath + 'X_train_RAW.csv', encoding='utf-8',index=False)\n",
    "X_val.to_csv(mypath + 'X_val_RAW.csv', encoding='utf-8',index=False)\n",
    "y_train.to_csv(mypath + 'y_train_RAW.csv', encoding='utf-8',index=False)\n",
    "y_val.to_csv(mypath + 'y_val_RAW.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c018d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process individual columns\n",
    "\n",
    "# Change dates to inbetween years\n",
    "def dates_to_days(df, col_list, base_date = '2018-01-01'):\n",
    "    #Convert date columns into datetime format\n",
    "    df['base_dt'] = pd.to_datetime(base_date)\n",
    "    df[col_list] = df[col_list].apply(pd.to_datetime)\n",
    "\n",
    "    for col in col_list:\n",
    "        df[col] = abs(df['base_dt'].dt.year - df[col].dt.year)\n",
    "\n",
    "    #Drop columns (base_dt)\n",
    "    df = df.drop('base_dt', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Categorize Area Code by 1000s\n",
    "def bin_area_code(df):\n",
    "    # Bin area codes by 1000s \n",
    "    labels = [\"{}_area_code\".format(i) for i in range(0, 10000, 1000)]\n",
    "    df['area_cat'] = pd.cut(df['customer_postal_code_m1'], range(0, 10005, 1000), right=False, labels=labels)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Get % Change from time point 1 to 2, 2 to 3, 1 to 3\n",
    "# def get_percent_change(df, col_list):\n",
    "def get_differences(df, col_list):\n",
    "\n",
    "    def difference(col1,col2):\n",
    "#     def percentage_change(col1,col2):\n",
    "#         change = ((col2 - col1) / col1) * 100\n",
    "        return col2-col1\n",
    "\n",
    "    for col in col_list:\n",
    "        df['{}_1'.format(col[2])] = difference(df[col[0]],df[col[1]]) \n",
    "        df['{}_2'.format(col[2])] = difference(df[col[1]],df[col[2]]) \n",
    "        df['{}_3'.format(col[2])] = difference(df[col[0]],df[col[2]]) \n",
    "\n",
    "        df['{}_1'.format(col[2])] = df['{}_1'.format(col[2])].fillna(0)\n",
    "        df['{}_2'.format(col[2])] = df['{}_2'.format(col[2])].fillna(0)\n",
    "        df['{}_3'.format(col[2])] = df['{}_3'.format(col[2])].fillna(0)    \n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "# Change NA to category\n",
    "def categorize_na(df, col_list):\n",
    "    for col in col_list:\n",
    "        df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247aaf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start preproecssing training data.\n",
      "\n",
      "1. Change dates to number of years.\n",
      "2. Categorize area code by 1000s.\n",
      "3. Get differences of balances between timepoints.\n",
      "Finished preprocess of training data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Pre-process training data ###\n",
    "print(f'\\nStart preproecssing training data.\\n')\n",
    "\n",
    "#1. Change dates to inbetween years\n",
    "print(f'1. Change dates to number of years.')\n",
    "list_dates = ['customer_since_all_m1', 'customer_since_bank_m1', 'customer_birth_date_m1']\n",
    "X_train = dates_to_days(X_train, list_dates, base_date = '2018-01-01')\n",
    "\n",
    "#2. Categorize Area Code by 1000s\n",
    "print(f'2. Categorize area code by 1000s.')\n",
    "X_train = bin_area_code(X_train)\n",
    "\n",
    "#3. Get % Change from time point 1 to 2, 2 to 3, 1 to 3\n",
    "print(f'3. Get differences of balances between timepoints.')\n",
    "list_balances = [['bal_insurance_21_m1', 'bal_insurance_21_m2', 'bal_insurance_21'],\n",
    "                 ['bal_insurance_23_m1', 'bal_insurance_23_m2', 'bal_insurance_23'],\n",
    "                 ['bal_personal_loan_m1', 'bal_personal_loan_m2', 'bal_personal_loan'],\n",
    "                 ['bal_mortgage_loan_m1', 'bal_mortgage_loan_m2', 'bal_mortgage_loan'],\n",
    "                 ['bal_current_account_m1', 'bal_current_account_m2', 'bal_current_account'],\n",
    "                 ['bal_pension_saving_m1', 'bal_pension_saving_m2', 'bal_pension_saving'],\n",
    "                 ['bal_savings_account_m1', 'bal_savings_account_m2', 'bal_savings_account'],\n",
    "                ]\n",
    "\n",
    "X_train = get_differences(X_train, list_balances)\n",
    "\n",
    "\n",
    "# print(f'4. Drop customer_education_m1 and duplicated features.\\n')\n",
    "# X_train = drop_features(['customer_education_m1'], X_train)\n",
    "\n",
    "print(f'Finished preprocess of training data.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8da658fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preproecssing validation data.\n",
      "\n",
      "1. Change dates to number of years.\n",
      "2. Categorize area code by 1000s.\n",
      "3. Get differences of balances between timepoints.\n",
      "Finished preprocess of training data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Pre-process validation data ###\n",
    "print(f'Start preproecssing validation data.\\n')\n",
    "\n",
    "#1. Change dates to inbetween years\n",
    "print(f'1. Change dates to number of years.')\n",
    "X_val = dates_to_days(X_val, list_dates, base_date = '2018-01-01')\n",
    "\n",
    "#2. Categorize Area Code by 1000s\n",
    "print(f'2. Categorize area code by 1000s.')\n",
    "X_val = bin_area_code(X_val)\n",
    "\n",
    "#3. Get % Change from time point 1 to 2, 2 to 3, 1 to 3\n",
    "print(f'3. Get differences of balances between timepoints.')\n",
    "X_val = get_differences(X_val, list_balances)\n",
    "\n",
    "# print(f'4. Drop customer_education_m1 and duplicated features.\\n')\n",
    "# X_val = drop_features(['customer_education_m1'], X_val)\n",
    "\n",
    "print(f'Finished preprocess of training data.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7334a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export data to ../data/team_data/data/ as X_train.csv, X_val.csv, y_train.csv, y_val.csv\n"
     ]
    }
   ],
   "source": [
    "# Export X_train, X_val, y_train, y_val\n",
    "print(f'Export data to {mypath} as X_train.csv, X_val.csv, y_train.csv, y_val.csv')\n",
    "X_train.to_csv(mypath + 'X_train_R.csv', encoding='utf-8',index=False)\n",
    "X_val.to_csv(mypath + 'X_val_R.csv', encoding='utf-8',index=False)\n",
    "y_train.to_csv(mypath + 'y_train_R.csv', encoding='utf-8',index=False)\n",
    "y_val.to_csv(mypath + 'y_val_R.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913550b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
