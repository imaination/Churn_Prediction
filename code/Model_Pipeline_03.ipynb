{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636438b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import load_data\n",
    "from ipynb.fs.full.Get_Base_Data_00 import Time\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,classification_report,recall_score,confusion_matrix, roc_auc_score, precision_score, f1_score, roc_curve, auc, plot_confusion_matrix,plot_roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Import Libraries for Modelling\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390b61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_250(y_val, y_pred):\n",
    "    # Top 250 Evaluation\n",
    "    print(f'Accuracy: {round(accuracy_score(y_val[:250], y_pred[:250]),4)}')\n",
    "    print(f'Recall: {round(recall_score(y_val[:250], y_pred[:250]),4)}')\n",
    "    print(f'ROC_AUC: {round(roc_auc_score(y_val[:250], y_pred[:250]),4)}')\n",
    "    print(f'Precision: {round(precision_score(y_val[:250], y_pred[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a712432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #Load Data\n",
    "    mypath = \"../data/\"\n",
    "    mydata = load_data.get_file_names(mypath)\n",
    "    data_files = load_data.load_copy_data(mydata, mypath)\n",
    "\n",
    "    data = data_files['data_merged']\n",
    "    X_train = data_files['X_train'].copy()\n",
    "    X_val = data_files['X_val'].copy()\n",
    "    y_train = data_files['y_train']['target'].copy()\n",
    "    y_val = data_files['y_val']['target'].copy()\n",
    "    \n",
    "    \n",
    "    # Features to preprocess\n",
    "\n",
    "    # Categorical Features to Preprocess\n",
    "    categorical_features = [\n",
    "        'homebanking_active_m1', 'homebanking_active_m2', 'homebanking_active',\n",
    "        'has_homebanking_m1', 'has_homebanking_m2', 'has_homebanking',\n",
    "        'has_insurance_21_m1', 'has_insurance_21_m2', 'has_insurance_21',\n",
    "        'has_insurance_23_m1', 'has_insurance_23_m2', 'has_insurance_23',\n",
    "        'has_life_insurance_fixed_cap_m1', 'has_life_insurance_fixed_cap_m2', 'has_life_insurance_fixed_cap',\n",
    "        'has_life_insurance_decreasing_cap_m1', 'has_life_insurance_decreasing_cap_m2', 'has_life_insurance_decreasing_cap',\n",
    "        'has_fire_car_other_insurance_m1', 'has_fire_car_other_insurance_m2', 'has_fire_car_other_insurance',\n",
    "        'has_personal_loan_m1', 'has_personal_loan_m2', 'has_personal_loan',\n",
    "        'has_mortgage_loan_m1', 'has_mortgage_loan_m2', 'has_mortgage_loan',\n",
    "        'has_current_account_m1', 'has_current_account_m2', 'has_current_account',\n",
    "        'has_pension_saving_m1', 'has_pension_saving_m2', 'has_pension_saving',\n",
    "        'has_savings_account_m1', 'has_savings_account_m2', 'has_savings_account',\n",
    "        'has_savings_account_starter_m1', 'has_savings_account_starter',\n",
    "        'has_current_account_starter_m1', 'has_current_account_starter_m2', 'has_current_account_starter',\n",
    "        'visits_distinct_so_m1', 'visits_distinct_so_m2', 'visits_distinct_so',\n",
    "        'visits_distinct_so_areas_m1', 'visits_distinct_so_areas_m2', 'visits_distinct_so_areas',\n",
    "        'customer_gender_m1',\n",
    "    #     'customer_postal_code_x', drop this, causes error...\n",
    "        'customer_occupation_code_m1',\n",
    "        'customer_self_employed_m1', 'customer_self_employed_m2', 'customer_self_employed',\n",
    "        'customer_education_m1',\n",
    "        'customer_children_m1', 'customer_children_m2', 'customer_children',\n",
    "        'customer_relationship_m1', 'customer_relationship_m2', 'customer_relationship',\n",
    "        'area_cat',\n",
    "    ]\n",
    "\n",
    "    # Numerical Features to Preprocess\n",
    "    numeric_features = [\n",
    "        'bal_insurance_21_m1', 'bal_insurance_21_m2', 'bal_insurance_21', \n",
    "        'bal_insurance_23_m1', 'bal_insurance_23_m2', 'bal_insurance_23',\n",
    "        'cap_life_insurance_fixed_cap_m1', 'cap_life_insurance_fixed_cap_m2', 'cap_life_insurance_fixed_cap',\n",
    "        'cap_life_insurance_decreasing_cap_m1', 'cap_life_insurance_decreasing_cap_m2', 'cap_life_insurance_decreasing_cap',\n",
    "        'prem_fire_car_other_insurance_m1', 'prem_fire_car_other_insurance_m2', 'prem_fire_car_other_insurance',\n",
    "        'bal_personal_loan_m1', 'bal_personal_loan_m2', 'bal_personal_loan',\n",
    "        'bal_mortgage_loan_m1', 'bal_mortgage_loan_m2', 'bal_mortgage_loan',\n",
    "        'bal_current_account_m1', 'bal_current_account_m2', 'bal_current_account',\n",
    "        'bal_pension_saving_m1', 'bal_pension_saving_m2', 'bal_pension_saving',\n",
    "        'bal_savings_account_m1', 'bal_savings_account_m2', 'bal_savings_account', \n",
    "        'bal_savings_account_starter_m1', 'bal_savings_account_starter_m2', 'bal_savings_account_starter',\n",
    "        'bal_current_account_starter_m1', 'bal_current_account_starter_m2', 'bal_current_account_starter',    \n",
    "        'customer_since_all_m1', \n",
    "        'customer_since_bank_m1',\n",
    "        'customer_birth_date_m1',\n",
    "    ]\n",
    "\n",
    "    # Check if including any non-existent columns\n",
    "    for col in categorical_features:\n",
    "        if col in X_train.columns:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'missing: {col}')\n",
    "\n",
    "    \n",
    "    # Replace NA with column mean, normalize numerical values\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('normalize', Normalizer()),\n",
    "    #     ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Replace NA with column mode, encode categorical value to 0/1\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OrdinalEncoder())\n",
    "    ])\n",
    "\n",
    "    # Pre-process pipeline that drops unnecessary features, transforms numerical and categorical values\n",
    "    preprocessor = ColumnTransformer(#remainder='passthrough',\n",
    "                                     transformers=[\n",
    "                                         ('numeric', numeric_transformer, numeric_features),\n",
    "                                         ('categorical', categorical_transformer, categorical_features)\n",
    "                                    ])\n",
    "\n",
    "    # Setting remainder=’passthrough’ will mean that all columns not specified in the list of “transformers” \n",
    "    # will be passed through without transformation, instead of being dropped.\n",
    "    \n",
    "    \n",
    "    # CatBoost \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "    #     ('oversample', SMOTE(sampling_strategy=0.4)),\n",
    "    #     ('undersample', RandomUnderSampler(sampling_strategy=0.8)),\n",
    "        ('oversample', RandomOverSampler(sampling_strategy=0.8)),\n",
    "        ('catboost', CatBoostClassifier(verbose=False,random_state=0)),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate Model\n",
    "    y_pred = pipeline.predict(X_val)  \n",
    "    evaluate_250(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b2aa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name: train_month_1\n",
      "file name: data_merged\n",
      "file name: train_month_2\n",
      "file name: y_val\n",
      "file name: X_train\n",
      "file name: X_val\n",
      "file name: test_month_1\n",
      "file name: test_month_3\n",
      "file name: y_train\n",
      "file name: test_month_2\n",
      "file name: train_month_3_with_target\n",
      "Accuracy: 0.956\n",
      "Recall: 0.2\n",
      "ROC_AUC: 0.5857\n",
      "Precision: 0.125\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3071c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DecisionTree\n",
    "\n",
    "# pipeline_dt = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('oversample', SMOTE(sampling_strategy=0.1)),\n",
    "#     ('undersample', RandomUnderSampler(sampling_strategy=0.5)),\n",
    "#     ('DecisionTree', DecisionTreeClassifier()),\n",
    "# ])\n",
    "\n",
    "# pipeline_dt.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate Model\n",
    "# y_pred_dt = pipeline_dt.predict(X_val)\n",
    "\n",
    "# # Top 250 Evaluation\n",
    "# print(f'Accuracy: {round(accuracy_score(y_val[:250], y_pred_dt[:250]),4)}')\n",
    "# print(f'Recall: {round(recall_score(y_val[:250], y_pred_dt[:250]),4)}')\n",
    "# print(f'ROC_AUC: {round(roc_auc_score(y_val[:250], y_pred_dt[:250]),4)}')\n",
    "# print(f'Precision: {round(precision_score(y_val[:250], y_pred_dt[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = RandomForestClassifier(n_estimators=100, max_depth=40,\n",
    "#                                min_samples_leaf=50,\n",
    "#                                n_jobs=-1, class_weight='balanced',\n",
    "#                                random_state=50)\n",
    "\n",
    "# pipeline_rf = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('oversample', RandomOverSampler(sampling_strategy=0.5)),\n",
    "#     ('RandomForest', model),\n",
    "# ])\n",
    "\n",
    "# pipeline_log.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate Model\n",
    "# y_pred_log = pipeline_log.predict(X_val)\n",
    "\n",
    "# # Top 250 Evaluation\n",
    "# print(f'Accuracy: {round(accuracy_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "# print(f'Recall: {round(recall_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "# print(f'ROC_AUC: {round(roc_auc_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "# print(f'Precision: {round(precision_score(y_val[:250], y_pred_log[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbde0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Logistic\n",
    "\n",
    "# pipeline_log = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('oversample', SMOTE(sampling_strategy=0.1)),\n",
    "#     ('undersample', RandomUnderSampler(sampling_strategy=0.5)),\n",
    "#     ('Logistic', LogisticRegression(random_state=0)),\n",
    "# ])\n",
    "\n",
    "# pipeline_log.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate Model\n",
    "# y_pred_log = pipeline_log.predict(X_val)\n",
    "\n",
    "# # Top 250 Evaluation\n",
    "# print(f'Accuracy: {round(accuracy_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "# print(f'Recall: {round(recall_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "# print(f'ROC_AUC: {round(roc_auc_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "# print(f'Precision: {round(precision_score(y_val[:250], y_pred_log[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1278296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.kaggle.com/code/ritesh2000/hyperparameter-tuning-using-pipelines-optuna/notebook\n",
    "\n",
    "# pipelines = [pipeline, pipeline_dt, pipeline_log, pipeline_rf]\n",
    "\n",
    "# best_accuracy=0.0\n",
    "# best_classifier=0\n",
    "# best_pipeline=\"\"\n",
    "\n",
    "# pipe_dict={0:'CatBoost',1:'Decision Tree',2:'Logistic Regression',3:'Random Forest'}\n",
    "\n",
    "# # Fit the pipelines\n",
    "# for pipe in pipelines: \n",
    "#     pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# for i,model in enumerate(pipelines):\n",
    "#     if model.score(X_val,y_val)>best_accuracy:\n",
    "#         best_accuracy=model.score(X_val,y_val)\n",
    "#         best_pipeline=model\n",
    "#         best_classifier=i\n",
    "# print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "\n",
    "# pipe = Pipeline([('classifier',RandomForestClassifier())])\n",
    "# # You can also the other classifier like by creating another dictionary inside grid_params.\n",
    "# grid_params = [{'classifier':[RandomForestClassifier()],\n",
    "#                 'classifier__n_estimators' : [10,20,30,40,50,60,70,80],\n",
    "#                 'classifier__criterion' : [\"gini\",\"entropy\"],\n",
    "#                 'classifier__max_depth' : [2,4,6,8,10],\n",
    "#                 'classifier__min_samples_split':[5,4,6,7,8],\n",
    "#                 'classifier__max_features':['auto', 'sqrt', 'log2']\n",
    "#                 }]\n",
    "\n",
    "# grid_search = GridSearchCV(pipe, grid_params, cv=5, verbose=0,n_jobs=-1,scoring=\"roc_auc\")\n",
    "\n",
    "# grid_search.fit(X_train,y_train)\n",
    "# best_accuracy = grid_search.best_score_\n",
    "# best_parameters = grid_search.best_params_\n",
    "# print(\"Best ROC_AUC: {:.2f} %\".format(best_accuracy*100))\n",
    "# print(\"Best Parameters:\", best_parameters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
