{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cd5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training data\n",
    "# Clean/preprocess/transform the data\n",
    "# Train a machine learning model\n",
    "# Evaluate and optimise the model\n",
    "# Clean/preprocess/transform new data\n",
    "# Fit the model on new data to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636438b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import load_data\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,classification_report,recall_score,confusion_matrix, roc_auc_score, precision_score, f1_score, roc_curve, auc, plot_confusion_matrix,plot_roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Import Libraries for Modelling\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.base import BaseEstimator\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import imblearn\n",
    "# from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9a9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name: train_month_1\n",
      "file name: data_merged\n",
      "file name: train_month_2\n",
      "file name: y_val\n",
      "file name: X_train\n",
      "file name: X_val\n",
      "file name: test_month_1\n",
      "file name: test_month_3\n",
      "file name: y_train\n",
      "file name: test_month_2\n",
      "file name: train_month_3_with_target\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "mypath = \"../data/\"\n",
    "mydata = load_data.get_file_names(mypath)\n",
    "data_files = load_data.load_copy_data(mydata, mypath)\n",
    "\n",
    "data = data_files['data_merged']\n",
    "X_train = data_files['X_train'].copy()\n",
    "X_val = data_files['X_val'].copy()\n",
    "y_train = data_files['y_train']['target'].copy()\n",
    "y_val = data_files['y_val']['target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e04e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to preprocess\n",
    "\n",
    "# Categorical Features to Preprocess\n",
    "categorical_features = [\n",
    "    'homebanking_active_x', 'homebanking_active_y', 'homebanking_active',\n",
    "    'has_homebanking_x', 'has_homebanking_y', 'has_homebanking',\n",
    "    'has_insurance_21_x', 'has_insurance_21_y', 'has_insurance_21',\n",
    "    'has_insurance_23_x', 'has_insurance_23_y', 'has_insurance_23',\n",
    "    'has_life_insurance_fixed_cap_x', 'has_life_insurance_fixed_cap_y', 'has_life_insurance_fixed_cap',\n",
    "    'has_life_insurance_decreasing_cap_x', 'has_life_insurance_decreasing_cap_y', 'has_life_insurance_decreasing_cap',\n",
    "    'has_fire_car_other_insurance_x', 'has_fire_car_other_insurance_y', 'has_fire_car_other_insurance',\n",
    "    'has_personal_loan_x', 'has_personal_loan_y', 'has_personal_loan',\n",
    "    'has_mortgage_loan_x', 'has_mortgage_loan_y', 'has_mortgage_loan',\n",
    "    'has_current_account_x', 'has_current_account_y', 'has_current_account',\n",
    "    'has_pension_saving_x', 'has_pension_saving_y', 'has_pension_saving',\n",
    "    'has_savings_account_x', 'has_savings_account_y', 'has_savings_account',\n",
    "    'has_savings_account_starter_x', 'has_savings_account_starter',\n",
    "    'has_current_account_starter_x', 'has_current_account_starter_y', 'has_current_account_starter',\n",
    "    'visits_distinct_so_x', 'visits_distinct_so_y', 'visits_distinct_so',\n",
    "    'visits_distinct_so_areas_x', 'visits_distinct_so_areas_y', 'visits_distinct_so_areas',\n",
    "    'customer_gender_x',\n",
    "#     'customer_postal_code_x', drop this, causes error...\n",
    "    'customer_occupation_code_x',\n",
    "    'customer_self_employed_x', 'customer_self_employed_y', 'customer_self_employed',\n",
    "    'customer_education_x',\n",
    "    'customer_children_x', 'customer_children_y', 'customer_children',\n",
    "    'customer_relationship_x', 'customer_relationship_y', 'customer_relationship',\n",
    "    'area_cat',\n",
    "]\n",
    "\n",
    "# Numerical Features to Preprocess\n",
    "numeric_features = [\n",
    "    'bal_insurance_21_x', 'bal_insurance_21_y', 'bal_insurance_21', \n",
    "    'bal_insurance_23_x', 'bal_insurance_23_y', 'bal_insurance_23',\n",
    "    'cap_life_insurance_fixed_cap_x', 'cap_life_insurance_fixed_cap_y', 'cap_life_insurance_fixed_cap',\n",
    "    'cap_life_insurance_decreasing_cap_x', 'cap_life_insurance_decreasing_cap_y', 'cap_life_insurance_decreasing_cap',\n",
    "    'prem_fire_car_other_insurance_x', 'prem_fire_car_other_insurance_y', 'prem_fire_car_other_insurance',\n",
    "    'bal_personal_loan_x', 'bal_personal_loan_y', 'bal_personal_loan',\n",
    "    'bal_mortgage_loan_x', 'bal_mortgage_loan_y', 'bal_mortgage_loan',\n",
    "    'bal_current_account_x', 'bal_current_account_y', 'bal_current_account',\n",
    "    'bal_pension_saving_x', 'bal_pension_saving_y', 'bal_pension_saving',\n",
    "    'bal_savings_account_x', 'bal_savings_account_y', 'bal_savings_account', \n",
    "    'bal_savings_account_starter_x', 'bal_savings_account_starter_y', 'bal_savings_account_starter',\n",
    "    'bal_current_account_starter_x', 'bal_current_account_starter_y', 'bal_current_account_starter',    \n",
    "    'customer_since_all_x', \n",
    "    'customer_since_bank_x',\n",
    "    'customer_birth_date_x',\n",
    "]\n",
    "\n",
    "# Check if including any non-existent columns\n",
    "for col in numeric_features:\n",
    "    if col in X_train.columns:\n",
    "        pass\n",
    "    else:\n",
    "        print(f'missing: {col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f540a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA with column mean, normalize numerical values\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('normalize', Normalizer()),\n",
    "#     ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Replace NA with column mode, encode categorical value to 0/1\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Pre-process pipeline that drops unnecessary features, transforms numerical and categorical values\n",
    "preprocessor = ColumnTransformer(#remainder='passthrough',\n",
    "                                 transformers=[\n",
    "#                                      ('drop_columns', 'drop', drop_features),\n",
    "                                     ('numeric', numeric_transformer, numeric_features),\n",
    "                                     ('categorical', categorical_transformer, categorical_features)\n",
    "                                ])\n",
    "\n",
    "# Setting remainder=’passthrough’ will mean that all columns not specified in the list of “transformers” \n",
    "# will be passed through without transformation, instead of being dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba064d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.944\n",
      "Recall: 0.2\n",
      "ROC_AUC: 0.5796\n",
      "Precision: 0.0909\n"
     ]
    }
   ],
   "source": [
    "# CatBoost \n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "#     ('oversample', SMOTE(sampling_strategy=0.4)),\n",
    "#     ('undersample', RandomUnderSampler(sampling_strategy=0.8)),\n",
    "    ('oversample', RandomOverSampler(sampling_strategy=0.8)),\n",
    "    ('catboost', CatBoostClassifier(verbose=False,random_state=0)),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Top 250 Evaluation\n",
    "print(f'Accuracy: {round(accuracy_score(y_val[:250], y_pred[:250]),4)}')\n",
    "print(f'Recall: {round(recall_score(y_val[:250], y_pred[:250]),4)}')\n",
    "print(f'ROC_AUC: {round(roc_auc_score(y_val[:250], y_pred[:250]),4)}')\n",
    "print(f'Precision: {round(precision_score(y_val[:250], y_pred[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f66d8943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.816\n",
      "Recall: 0.2\n",
      "ROC_AUC: 0.5143\n",
      "Precision: 0.0233\n"
     ]
    }
   ],
   "source": [
    "#DecisionTree\n",
    "\n",
    "pipeline_dt = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('oversample', SMOTE(sampling_strategy=0.1)),\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy=0.5)),\n",
    "    ('DecisionTree', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "pipeline_dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred_dt = pipeline_dt.predict(X_val)\n",
    "\n",
    "# Top 250 Evaluation\n",
    "print(f'Accuracy: {round(accuracy_score(y_val[:250], y_pred_dt[:250]),4)}')\n",
    "print(f'Recall: {round(recall_score(y_val[:250], y_pred_dt[:250]),4)}')\n",
    "print(f'ROC_AUC: {round(roc_auc_score(y_val[:250], y_pred_dt[:250]),4)}')\n",
    "print(f'Precision: {round(precision_score(y_val[:250], y_pred_dt[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2efb43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Recall: 0.2\n",
      "ROC_AUC: 0.5571\n",
      "Precision: 0.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic\n",
    "\n",
    "pipeline_log = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('oversample', SMOTE(sampling_strategy=0.1)),\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy=0.5)),\n",
    "    ('Logistic', LogisticRegression(random_state=0)),\n",
    "])\n",
    "\n",
    "pipeline_log.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred_log = pipeline_log.predict(X_val)\n",
    "\n",
    "# Top 250 Evaluation\n",
    "print(f'Accuracy: {round(accuracy_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "print(f'Recall: {round(recall_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "print(f'ROC_AUC: {round(roc_auc_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "print(f'Precision: {round(precision_score(y_val[:250], y_pred_log[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67a1dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856\n",
      "Recall: 0.2\n",
      "ROC_AUC: 0.5347\n",
      "Precision: 0.0303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=40,\n",
    "                               min_samples_leaf=50,\n",
    "                               n_jobs=-1, class_weight='balanced',\n",
    "                               random_state=50)\n",
    "\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('oversample', RandomOverSampler(sampling_strategy=0.5)),\n",
    "    ('RandomForest', model),\n",
    "])\n",
    "\n",
    "pipeline_log.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred_log = pipeline_log.predict(X_val)\n",
    "\n",
    "# Top 250 Evaluation\n",
    "print(f'Accuracy: {round(accuracy_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "print(f'Recall: {round(recall_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "print(f'ROC_AUC: {round(roc_auc_score(y_val[:250], y_pred_log[:250]),4)}')\n",
    "print(f'Precision: {round(precision_score(y_val[:250], y_pred_log[:250]),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3c250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a712432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b2aa53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34456de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c288ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7139c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/ritesh2000/hyperparameter-tuning-using-pipelines-optuna/notebook\n",
    "\n",
    "pipelines = [pipeline, pipeline_dt, pipeline_log, pipeline_rf]\n",
    "\n",
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\"\n",
    "\n",
    "pipe_dict={0:'CatBoost',1:'Decision Tree',2:'Logistic Regression',3:'Random Forest'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines: \n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78de9717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy:CatBoost\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_val,y_val)>best_accuracy:\n",
    "        best_accuracy=model.score(X_val,y_val)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d7cc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1278296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6000 fits failed out of a total of 6000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 327, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/pandas/core/generic.py\", line 2072, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'Unknown'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xc/tvrxkd8d2d71ksnxgn8wf9t40000gn/T/ipykernel_19594/196680376.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/opt/anaconda3/envs/aa_2022/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Unknown'"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('classifier',RandomForestClassifier())])\n",
    "# You can also the other classifier like by creating another dictionary inside grid_params.\n",
    "grid_params = [{'classifier':[RandomForestClassifier()],\n",
    "                'classifier__n_estimators' : [10,20,30,40,50,60,70,80],\n",
    "                'classifier__criterion' : [\"gini\",\"entropy\"],\n",
    "                'classifier__max_depth' : [2,4,6,8,10],\n",
    "                'classifier__min_samples_split':[5,4,6,7,8],\n",
    "                'classifier__max_features':['auto', 'sqrt', 'log2']\n",
    "                }]\n",
    "\n",
    "grid_search = GridSearchCV(pipe, grid_params, cv=5, verbose=0,n_jobs=-1,scoring=\"roc_auc\")\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best ROC_AUC: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
